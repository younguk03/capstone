{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6813795-d7f8-4219-8c64-26b589ff79b1",
   "metadata": {},
   "source": [
    "# 5.0 Creating Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69fef7-aff4-49e5-ae96-d1c1525da5af",
   "metadata": {},
   "source": [
    "### In this notebook will create two functions i.e function_1 and function_2\n",
    "### \n",
    "In function_1 will create entire pipeline to predict the output i.e for any given query will predict the output of it.\n",
    "### \n",
    "In function_2 will create entire pipeline to output the performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828c6810-d210-4564-bd47-196e6a918646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e4ac36-afb2-4f5f-be9f-981bd8cbe137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cannot open. Error: [Errno 2] No such file or directory: 'train_bow'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('train_bow', 'rb') as f:\n",
    "        train_bow = pickle.load(f)\n",
    "        print(\"Opened successfully\")\n",
    "except Exception as e:\n",
    "    print(\"File cannot open. Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d1c0ae3-3d2f-4c26-ac7d-b938564dde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to print the classification metrics\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    B =(C/C.sum(axis=0))\n",
    "    labels = [0,1]\n",
    "    plt.figure(figsize = (20,5))\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    print(\"f1-score on the data is  {}\".format(f1_score(test_y,predict_y)))\n",
    "    print(\"Run Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f8e8c43-d8cb-49b5-a5f3-345bfaa69bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Function_1 will output the prediction whether it belongs to class 1 or class 0 for a given SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bae8a8de-c691-4703-8a94-a3e1d0f9dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(query):\n",
    "    preprocessed_query = []\n",
    "    \n",
    "    def process(x,pattern):\n",
    "        r = re.compile(pattern)\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    \n",
    "    def combined_keywords(x):\n",
    "        r = re.compile(r'null')\n",
    "        m = re.compile(r'chr')\n",
    "        n = re.compile(r'char')\n",
    "        l = r.findall(x)\n",
    "        k = m.findall(x)\n",
    "        j = n.findall(x)\n",
    "        return len(l) + len(k) + len(j)\n",
    "    \n",
    "    def genuine(x):\n",
    "        count = 0\n",
    "        genuine_keys = ['select','top','order','fetch','join','avg','count','sum','rows']\n",
    "        for i in x.split():\n",
    "            if(i in genuine_keys):\n",
    "                count = count + 1\n",
    "        return count\n",
    "    \n",
    "    preprocessed_query.append(process(query,\"'\"))\n",
    "    preprocessed_query.append(process(query,'\"'))\n",
    "    preprocessed_query.append(process(query,\"[!\\\"#$%&\\'()*+,-.\\/:;<=>?@[\\\\]^_`{|}~]\"))\n",
    "    preprocessed_query.append(process(query,'(--)'))\n",
    "    preprocessed_query.append(process(query,'(\\/\\*)'))\n",
    "    preprocessed_query.append(process(query,'\\s+'))\n",
    "    preprocessed_query.append(process(query,\"%\"))\n",
    "    preprocessed_query.append(process(query,'\\snot\\s|\\sand\\s|\\sor\\s|\\sxor\\s|&&|\\|\\||!'))\n",
    "    preprocessed_query.append(process(query,\"'\\+|-|[^\\/]\\*|\\/[^\\*]'\"))\n",
    "    preprocessed_query.append(process(query,\"null\"))\n",
    "    preprocessed_query.append(process(query,'0[xX][0-9a-fA-F]+\\s'))\n",
    "    preprocessed_query.append(process(query,'[a-zA-Z]'))\n",
    "    preprocessed_query.append(process(query,'[0-9]'))\n",
    "    preprocessed_query.append(combined_keywords(query))\n",
    "    preprocessed_query.append(genuine(query))\n",
    "    \n",
    "    return preprocessed_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3abb68a2-fded-47d3-8e27-9701c547c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function_1(query):\n",
    "    li = []\n",
    "    query = query.lower()#converting query to lowercase\n",
    "    arr = preprocess(query)#preprocessing the query\n",
    "    li.append(query)\n",
    "    unigram_bow = train_bow.transform(li)\n",
    "    \n",
    "    combine = hstack((unigram_bow,arr))\n",
    "    \n",
    "    #loading the model\n",
    "    xgboost_model = joblib.load('saved_model_unigram_bow.pkl')\n",
    "    \n",
    "    #predicting the output from the loaded model\n",
    "    predict = xgboost_model.predict(combine)\n",
    "    \n",
    "    for i in predict:\n",
    "        if(i == 1):\n",
    "              print(\"the query passed belongs to class {} i.e the query is SQL injection query\".format(i))\n",
    "        else:\n",
    "              print(\"the query passed belongs to class {} i.e the query is not a  SQL injection query\".format(i))\n",
    "    final_function_1(\"select   (  case when   (  1275  =  7674  )   then 1275 else 1275*  (  select 1275 from information_schema.character_sets  )   end  )  #\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3542b2a6-8b41-4449-a857-2b36ae1ecdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function_1\n",
    "def function_1(query):\n",
    "    '''\n",
    "    query parameter is a list of queries given to predict that it is Sql injection or not.\n",
    "    \n",
    "    '''\n",
    "    #first will create the dataframe for list of queries\n",
    "    data = pd.DataFrame()\n",
    "    data['Query'] = query\n",
    "    \n",
    "    #convert the query to lowercase sentence\n",
    "    data['Query'] = data['Query'].apply(lambda x : x.lower())\n",
    "    \n",
    "                \n",
    "    #number of single quotation in a query\n",
    "    def single_qt(x):\n",
    "        r = re.compile(r\"'\")\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_single_qts'] = data['Query'].apply(single_qt)\n",
    "\n",
    "\n",
    "    #number of double quotation in a query\n",
    "    def double_qt(x):\n",
    "        r = re.compile(r'\"')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_double_qts'] = data['Query'].apply(double_qt)\n",
    "\n",
    "     #number of punctuations \n",
    "    def punctuation(x):\n",
    "        r = re.compile(\"[!\\\"#$%&\\'()*+,-.\\/:;<=>?@[\\\\]^_`{|}~]\")\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_punct'] = data['Query'].apply(punctuation)\n",
    "\n",
    "\n",
    "    #number of single line comment\n",
    "    def sin_comm(x):\n",
    "        r = re.compile(r'(--)')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_single_cmnt'] = data['Query'].apply(sin_comm)\n",
    "\n",
    "    #number of multiline comments\n",
    "    def mult_comm(x):\n",
    "        r = re.compile(r'(\\/\\*)')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_mult_cmnt'] = data['Query'].apply(mult_comm)\n",
    "\n",
    "\n",
    "     #number of white spaces in a query\n",
    "    def space(x):\n",
    "        r = re.compile(r'\\s+')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_space'] = data['Query'].apply(space) \n",
    "\n",
    "\n",
    "     #number of percentage(%) symbols in a query.\n",
    "    def perc(x):\n",
    "        r = re.compile(r'%')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_perc'] = data['Query'].apply(perc)\n",
    "\n",
    "\n",
    "      #total number of logical operator in a query\n",
    "         #logical operators are and,or,not,xor,&&,||,!\n",
    "      #https://stackoverflow.com/questions/43079182/how-to-find-logic-operators-in-string-with-regex\n",
    "    def logical(x):\n",
    "        r = re.compile(r'\\snot\\s|\\sand\\s|\\sor\\s|\\sxor\\s|&&|\\|\\||!')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_log_opt'] = data['Query'].apply(logical)\n",
    "\n",
    "\n",
    "      #total number of arithmetic operators\n",
    "    def arithmetic(x):\n",
    "        r = re.compile(r'\\+|-|[^\\/]\\*|\\/[^\\*]')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_arith'] = data['Query'].apply(arithmetic)\n",
    "\n",
    "\n",
    "       #number of null values in a query\n",
    "    def null_val(x):\n",
    "        r = re.compile(r'null')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_null'] = data['Query'].apply(null_val)\n",
    "\n",
    "\n",
    "     #number of hexadecimal values\n",
    "    def hexa(x):\n",
    "        r = re.compile(r'0[xX][0-9a-fA-F]+\\s')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_hexa'] = data['Query'].apply(hexa)\n",
    "\n",
    "\n",
    "    #number of alphabets\n",
    "    def alphabet(x):\n",
    "        r = re.compile(r'[a-zA-Z]')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_alpha'] = data['Query'].apply(alphabet)\n",
    "\n",
    "\n",
    "     #number of digits\n",
    "    def digit(x):\n",
    "        r = re.compile(r'[0-9]')\n",
    "        l = r.findall(x)\n",
    "        return len(l)\n",
    "    data['no_digit']  =data['Query'].apply(digit)\n",
    "\n",
    "\n",
    "       #length of chr+char+null keywords\n",
    "    def combined_keywords(x):\n",
    "        r = re.compile(r'null')\n",
    "        m = re.compile(r'chr')\n",
    "        n = re.compile(r'char')\n",
    "        l = r.findall(x)\n",
    "        k = m.findall(x)\n",
    "        j = n.findall(x)\n",
    "        return len(l) + len(k) + len(j)\n",
    "    data['len_of_chr_char_null'] = data['Query'].apply(combined_keywords)\n",
    "\n",
    "\n",
    "     #genuine_keywords\n",
    "     #genuine keywords are based on wordclouds : select,top,order,fetch,join,avg,count,sum,rows.\n",
    "     #will check how many number of these keywords are present in each query.\n",
    "\n",
    "    def genuine(x):\n",
    "        count = 0\n",
    "        genuine_keys = ['select','top','order','fetch','join','avg','count','sum','rows']\n",
    "        for i in x.split():\n",
    "            if(i in genuine_keys):\n",
    "                count = count + 1\n",
    "        return count\n",
    "\n",
    "    data['genuine_keywords'] = data['Query'].apply(genuine)\n",
    "        \n",
    "    #because in the model building we come to know that unigram BOW encoding provides better f1-score\n",
    "    unigram_bow = train_bow.transform(data['Query'].values)\n",
    "    \n",
    " \n",
    "    #finally will concatenate unigram_bow and above generated features\n",
    "    data_bow_unigram = hstack((unigram_bow,np.array(data['no_single_qts']).reshape(-1,1),np.array(data['no_double_qts']).reshape(-1,1),np.array(data['no_punct']).reshape(-1,1),np.array(data['no_single_cmnt']).reshape(-1,1),np.array(data['no_mult_cmnt']).reshape(-1,1),np.array(data['no_space']).reshape(-1,1),np.array(data['no_perc']).reshape(-1,1),np.array(data['no_log_opt']).reshape(-1,1),np.array(data['no_arith']).reshape(-1,1),np.array(data['no_null']).reshape(-1,1),np.array(data['no_hexa']).reshape(-1,1),np.array(data['no_alpha']).reshape(-1,1),np.array(data['no_digit']).reshape(-1,1),np.array(data['len_of_chr_char_null']).reshape(-1,1),np.array(data['genuine_keywords']).reshape(-1,1)))\n",
    "    #loading the XGboost model for unigram bow encoding\n",
    "    xgboost_model = joblib.load('saved_model_unigram_bow.pkl')\n",
    "    \n",
    "    #predicting the output from the loaded model\n",
    "    predict = xgboost_model.predict(data_bow_unigram)\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        if(predict[i] == 1):\n",
    "            print(\"the {} query passed belongs to class {} i.e the query is SQL injection query\".format(i,predict[i]))\n",
    "        else:\n",
    "            print(\"the {} query passed belongs to class {} i.e the query is not a  SQL injection query\".format(i,predict[i]))\n",
    "    return predict\n",
    "    function_1([\"create user name identified by pass123 temporary tablespace temp default tablespace users;\",\" or pg_sleep ( __TIME__ ) --\",\"SELECT sure FROM silent UNION SELECT sides FROM excellent ORDER BY wing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b61e06-df62-4f5b-aa7f-bb691c92685a",
   "metadata": {},
   "source": [
    "# 5.2 function_2 will output the classification metrics for given list of query and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "564d27be-c74a-499a-b57b-7f0faad7e629",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 55\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#calling the function_2 method to print the classification metrics\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#first will create list of tuples of queries and labels\u001b[39;00m\n\u001b[0;32m     48\u001b[0m data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate user name identified by pass123 temporary tablespace temp default tablespace users;\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     49\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or pg_sleep ( __TIME__ ) --\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     50\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT sure FROM silent UNION SELECT sides FROM excellent ORDER BY wing\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     51\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect   (  case when   (  1275  =  7674  )   then 1275 else 1275*  (  select 1275 from information_schema.character_sets  )   end  )  #\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     52\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124motia\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     53\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoudrey\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m---> 55\u001b[0m \u001b[43mfinal_function_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 42\u001b[0m, in \u001b[0;36mfinal_function_2\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     39\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(i[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#will call function_1 on above query lists to get predicted labels\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m plot_confusion_matrix(labels,pred_labels)\n",
      "Cell \u001b[1;32mIn[28], line 146\u001b[0m, in \u001b[0;36mfunction_1\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    143\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenuine_keywords\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(genuine)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m#because in the model building we come to know that unigram BOW encoding provides better f1-score\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m unigram_bow \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_bow\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m#finally will concatenate unigram_bow and above generated features\u001b[39;00m\n\u001b[0;32m    150\u001b[0m data_bow_unigram \u001b[38;5;241m=\u001b[39m hstack((unigram_bow,np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_single_qts\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_double_qts\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_punct\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_single_cmnt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_mult_cmnt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_space\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_perc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_log_opt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_arith\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_null\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_hexa\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_alpha\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_digit\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen_of_chr_char_null\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenuine_keywords\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_bow' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = [\n",
    "    (\"create user name identified by pass123 temporary tablespace temp default tablespace users;\", 1),\n",
    "    (\" or pg_sleep ( __TIME__ ) --\", 1),\n",
    "    (\"SELECT sure FROM silent UNION SELECT sides FROM excellent ORDER BY wing\", 0),\n",
    "    ('select (case when (1275 = 7674) then 1275 else 1275*(select 1275 from information_schema.character_sets) end)#', 1),\n",
    "    ('otia', 0),\n",
    "    ('joudrey', 0)\n",
    "]\n",
    "\n",
    "# DataFrame 변환\n",
    "df = pd.DataFrame(data, columns=['value', 'label'])\n",
    "\n",
    "# dummy 컬럼 추가\n",
    "df['url'] = 'http://dummy-url.com'\n",
    "df['param'] = 'query'\n",
    "\n",
    "# 열 순서 정리\n",
    "df = df[['url', 'param', 'value', 'label']]\n",
    "\n",
    "# 폴더 생성 후 CSV 저장\n",
    "os.makedirs('data', exist_ok=True)\n",
    "df.to_csv('data/sqli_dataset.csv', index=False)\n",
    "\n",
    "\n",
    "def final_function_2(data):\n",
    "    '''\n",
    "    data parameter is a list of tuples where 1st argument is sql query and respective labels\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #first will separate query and labels store it in separate lists\n",
    "    query = []\n",
    "    labels = []\n",
    "    for i in data:\n",
    "        query.append(i[0])\n",
    "        labels.append(i[1])\n",
    "    \n",
    "    #will call function_1 on above query lists to get predicted labels\n",
    "    pred_labels = function_1(query)\n",
    "    plot_confusion_matrix(labels,pred_labels)\n",
    "    \n",
    "#calling the function_2 method to print the classification metrics\n",
    "#first will create list of tuples of queries and labels\n",
    "\n",
    "data = [(\"create user name identified by pass123 temporary tablespace temp default tablespace users;\",1),\n",
    "        (\" or pg_sleep ( __TIME__ ) --\",1),\n",
    "        (\"SELECT sure FROM silent UNION SELECT sides FROM excellent ORDER BY wing\",0),\n",
    "        ('select   (  case when   (  1275  =  7674  )   then 1275 else 1275*  (  select 1275 from information_schema.character_sets  )   end  )  #',1),\n",
    "        ('otia',0),\n",
    "        ('joudrey',0)]\n",
    "         \n",
    "final_function_2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd22db-0395-40d2-be05-8299ebf7f87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
