{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:15:49) [MSC v.1941 64 bit (AMD64)]\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.2\n",
      "SciPy version: 1.13.1\n",
      "scikit-learn version: 1.4.2\n",
      "Seaborn version: 0.13.2\n",
      "Matplotlib version: 3.9.2\n",
      "TensorFlow version: 2.10.0\n",
      "Keras version: 2.10.0\n",
      "TensorFlow Text version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import seaborn\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import keras\n",
    "\n",
    "# Check versions\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"SciPy version:\", scipy.__version__)\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"Seaborn version:\", seaborn.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"TensorFlow Text version:\", tf_text.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qRPM1HZpVe_9"
   },
   "outputs": [],
   "source": [
    "#importing the neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "import tokenization\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_auc_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "h4QWN6AoU9Qa",
    "outputId": "d614f959-0891-4dba-a2a6-a2fd89cdabd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been extracted to: extracted_files\n",
      "Extracted files:\n",
      "['Tokenization.py']\n",
      "Error while running the script: Command '['python', 'extracted_files\\\\Tokenization.py']' returned non-zero exit status 1.\n",
      "Standard Output:\n",
      " \n",
      "Error Output:\n",
      " C:\\Users\\ritid\\anaconda3\\envs\\tf_env_3.10\\python.exe: can't find '__main__' module in 'C:\\\\Users\\\\ritid\\\\extracted_files\\\\Tokenization.py'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Step 1: Define the path to your zip file\n",
    "zip_file_path = \"Tokenization.py.zip\"\n",
    "\n",
    "# Step 2: Define the extraction directory\n",
    "extraction_dir = \"extracted_files\"\n",
    "\n",
    "# Step 3: Create the extraction directory if it doesn't exist\n",
    "if not os.path.exists(extraction_dir):\n",
    "    os.makedirs(extraction_dir)\n",
    "\n",
    "# Step 4: Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir)\n",
    "\n",
    "print(f\"Files have been extracted to: {extraction_dir}\")\n",
    "\n",
    "# Step 5: List the extracted files\n",
    "print(\"Extracted files:\")\n",
    "print(os.listdir(extraction_dir))\n",
    "\n",
    "# Step 6: Construct the full path to the Tokenization.py file\n",
    "file_path = os.path.join(extraction_dir, \"Tokenization.py\")\n",
    "\n",
    "# Step 7: Use subprocess to run the Python script and capture errors\n",
    "try:\n",
    "    result = subprocess.run([\"python\", file_path], capture_output=True, text=True, check=True)\n",
    "    print(\"Script ran successfully!\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error while running the script: {e}\")\n",
    "    print(\"Standard Output:\\n\", e.stdout)\n",
    "    print(\"Error Output:\\n\", e.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "J5ziAG1bVa90"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('feature_extracted_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TzKQld-QWFdu"
   },
   "outputs": [],
   "source": [
    "#will take out only query and label columns only\n",
    "data = data[['Query','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0hUiU5auWVRK",
    "outputId": "2dbb1172-ef90-4eaf-9e17-1effdcfe7493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" or pg_sleep  (  __time__  )  --</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create user name identified by pass123 tempora...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and 1  =  utl_inaddr.get_host_address   (    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>select * from users where id  =  '1' or @ @1 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select * from users where id  =  1 or 1#\"  ( ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  Label\n",
       "0                  \" or pg_sleep  (  __time__  )  --      1\n",
       "1  create user name identified by pass123 tempora...      1\n",
       "2   and 1  =  utl_inaddr.get_host_address   (    ...      1\n",
       "3   select * from users where id  =  '1' or @ @1 ...      1\n",
       "4   select * from users where id  =  1 or 1#\"  ( ...      1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "JbGvtAMNW2O7"
   },
   "outputs": [],
   "source": [
    "y  = data['Label']\n",
    "x = data.drop('Label',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "sruh20-niidn"
   },
   "outputs": [],
   "source": [
    "#splitting the data into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HtvDw233nTR",
    "outputId": "ac15edb1-c09e-4577-d60e-a79243778b6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21631, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gO7EuVI33p6w",
    "outputId": "acc95f36-5253-4272-9657-5f4ad5848925"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9271, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvTtPIXKlToO"
   },
   "source": [
    "Will choose maximum sequence length to be 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6.1 Bert Pretrained model loading </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "max_seq_length = 400  # Your choice here.\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                    name=\"segment_ids\")\n",
    "bert_layer = hub.KerasLayer(\"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-l-12-h-768-a-12/1\",\n",
    "                            trainable=True)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "#Bert model\n",
    "#We are using only pooled output not sequence out. \n",
    "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDOegQHPl91O",
    "outputId": "719c4633-6f45-4743-da55-e6df0160024f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 128, 768)]                'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "1QJc-d4_mFJO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from bert import tokenization\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer=tokenization.FullTokenizer(vocab_file,do_lower_case )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6.2 Tokenization </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import flags\n",
    "\n",
    "# Manually set the value of the flag before tokenization\n",
    "flags.FLAGS.preserve_unused_tokens = False\n",
    "\n",
    "# Now you can call the tokenizer function\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokens(text_input):\n",
    "    li_tokens = []\n",
    "    li_tokens_to_ids = []\n",
    "    li_mask = []\n",
    "    li_segment = []\n",
    "\n",
    "    for i in range(len(text_input)):\n",
    "        token = tokenizer.tokenize(text_input[i])\n",
    "\n",
    "        if len(token) > max_seq_length - 2:\n",
    "            token = token[0:(max_seq_length - 2)]\n",
    "        \n",
    "        token = ['[CLS]', *token, '[SEP]']\n",
    "        \n",
    "        if len(token) < max_seq_length:\n",
    "            pad_to_add = max_seq_length - len(token)\n",
    "            for _ in range(pad_to_add):\n",
    "                token.append('[PAD]')\n",
    "        \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(token)\n",
    "        li_tokens.append(token)\n",
    "        li_tokens_to_ids.append(input_ids)\n",
    "        li_mask.append([1 if i > 0 else 0 for i in input_ids])\n",
    "        li_segment.append([0] * max_seq_length)\n",
    "    \n",
    "    return np.array(li_tokens), np.array(li_tokens_to_ids), np.array(li_mask), np.array(li_segment)\n",
    "\n",
    "# Now you can call the function with your data\n",
    "X_train_tokens_, X_train_tokens, X_train_mask, X_train_segment = tokens(x_train['Query'].values)\n",
    "X_test_tokens_, X_test_tokens, X_test_mask, X_test_segment = tokens(x_test['Query'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmYTmpJ_m9RZ",
    "outputId": "85cf44f3-ef50-4ae5-fb98-7eb7c0c9359f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]' '1' '%' '\"' ')' ')' '(' 'select' '(' 'case' 'when' '(' '54'\n",
      " '##51' '=' '54' '##51' ')' 'then' 'reg' '##ex' '##p' '_' 'sub' '##st'\n",
      " '##ring' '(' 'repeat' '(' 'right' '(' 'char' '(' '54' '##51' ')' ',' '0'\n",
      " ')' ',' '5000' '##00' '##00' '##0' ')' ',' 'null' ')' 'else' 'char' '('\n",
      " '108' ')' '|' '|' 'char' '(' '76' ')' '|' '|' 'char' '(' '112' ')' '|'\n",
      " '|' 'char' '(' '116' ')' 'end' ')' 'from' 'information' '_' 'sc' '##hema'\n",
      " '.' 'system' '_' 'users' ')' 'and' '(' '(' '\"' '%' '\"' '=' '\"' '[SEP]'\n",
      " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
      " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
      " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
      " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]']\n",
      "[  101  1015  1003  1000  1007  1007  1006  7276  1006  2553  2043  1006\n",
      "  5139 22203  1027  5139 22203  1007  2059 19723 10288  2361  1035  4942\n",
      "  3367  4892  1006  9377  1006  2157  1006 25869  1006  5139 22203  1007\n",
      "  1010  1014  1007  1010 13509  8889  8889  2692  1007  1010 19701  1007\n",
      "  2842 25869  1006 10715  1007  1064  1064 25869  1006  6146  1007  1064\n",
      "  1064 25869  1006 11176  1007  1064  1064 25869  1006 12904  1007  2203\n",
      "  1007  2013  2592  1035  8040 28433  1012  2291  1035  5198  1007  1998\n",
      "  1006  1006  1000  1003  1000  1027  1000   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens_[0])\n",
    "\n",
    "print(X_train_tokens[0])\n",
    "print(X_train_mask[0])\n",
    "print(X_train_segment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbrOG1SlnCHA",
    "outputId": "48291744-c594-4ab2-e7e1-9f09a7e6f946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'input_word_ids')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'input_mask')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'segment_ids')>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting embeddings from bert model\n",
    "bert_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeKSnfGhnGyC",
    "outputId": "fc64156a-ccae-4c7a-fce1-6b8aee7d2a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer_1')>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "3KMkEEQUnKXH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/676 [==============================] - 3742s 6s/step\n",
      "290/290 [==============================] - 1553s 5s/step\n"
     ]
    }
   ],
   "source": [
    "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])\n",
    "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "KqiXST2l8bRv"
   },
   "outputs": [],
   "source": [
    "train_y = tf.keras.utils.to_categorical(y_train)\n",
    "test_y = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "dqbfyyjWnSnC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the log directory\n",
    "log_dir = os.path.join(\"logs\", 'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# Remove the directory if it exists (cross-platform way)\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "# Now, create the TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
    "\n",
    "# Example: Assuming you have a model, you can use it like this:\n",
    "# model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "tNgBhTGuoqCF"
   },
   "outputs": [],
   "source": [
    "#creating custom callbacks for f1-score metrics\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "  def __init__(self,validation_data):\n",
    "    self.x_test = validation_data[0]\n",
    "    self.y_test = validation_data[1]\n",
    "\n",
    "  def on_train_begin(self, logs={}):\n",
    "        self.history={'loss': [],'accuracy': [],'val_loss': [],'val_accuracy': [],'val_f1': []}\n",
    "  def on_epoch_end(self,epoch,logs = {}):\n",
    "    val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "    val_label = np.argmax(val_predict,axis = 1)\n",
    "    val_target = np.argmax(self.y_test,axis = 1)\n",
    "    val_f1 = f1_score(val_target,val_label)\n",
    "    self.history['val_f1'].append(val_f1)\n",
    "    print(\"val_f1_score\",val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "Ustgwk0ang4N"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,mode = \"max\",\n",
    "                                                 save_weights_only=True,save_best_only = True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "13WyacRNnzDm"
   },
   "outputs": [],
   "source": [
    "#creating objects for metrics custom callback\n",
    "score = Metrics((X_test_pooled_output,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "mAeOpbYNnjaF"
   },
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(X_train_pooled_output.shape[1],))\n",
    "dense_0 = Dense(524,activation = \"relu\")(input_layer)\n",
    "dense_ = Dense(256,activation=\"relu\")(dense_0)\n",
    "drop_0 = Dropout(0.5)(dense_)\n",
    "dense_1 = Dense(128,activation = \"relu\")(drop_0)\n",
    "drop_1 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(64,activation= 'relu')(drop_1)\n",
    "drop_2 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(32,activation='relu')(drop_2)\n",
    "out = Dense(2,activation = \"softmax\")(dense_3)\n",
    "model = Model(inputs = input_layer,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-wsfroVqMXu",
    "outputId": "f37ef3d0-dfa5-47e3-dc3a-7afbfd0c3de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 768)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 524)               402956    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               134400    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 580,654\n",
      "Trainable params: 580,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdXjKlKTnmfd",
    "outputId": "d54b6b5d-65ac-41db-a1a8-be5207b2c50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "668/676 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 1: val_loss improved from -inf to 0.09964, saving model to training_1\\cp.ckpt\n",
      "290/290 [==============================] - 1s 2ms/step\n",
      "val_f1_score 0.9697589481373265\n",
      "676/676 [==============================] - 6s 7ms/step - loss: 0.2235 - val_loss: 0.0996\n",
      "Epoch 2/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0978\n",
      "Epoch 2: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9694323144104804\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0977 - val_loss: 0.0720\n",
      "Epoch 3/20\n",
      "669/676 [============================>.] - ETA: 0s - loss: 0.0607\n",
      "Epoch 3: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 2ms/step\n",
      "val_f1_score 0.9872856298048492\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0602 - val_loss: 0.0362\n",
      "Epoch 4/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0548\n",
      "Epoch 4: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 2ms/step\n",
      "val_f1_score 0.9818607372732592\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0547 - val_loss: 0.0565\n",
      "Epoch 5/20\n",
      "667/676 [============================>.] - ETA: 0s - loss: 0.0489\n",
      "Epoch 5: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.988780631827576\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0485 - val_loss: 0.0305\n",
      "Epoch 6/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0434\n",
      "Epoch 6: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9886212501847199\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0436 - val_loss: 0.0389\n",
      "Epoch 7/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0474\n",
      "Epoch 7: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9910042766553606\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0474 - val_loss: 0.0336\n",
      "Epoch 8/20\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0331\n",
      "Epoch 8: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9891686182669789\n",
      "676/676 [==============================] - 6s 9ms/step - loss: 0.0329 - val_loss: 0.0251\n",
      "Epoch 9/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 0.0380\n",
      "Epoch 9: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9879941434846267\n",
      "676/676 [==============================] - 6s 9ms/step - loss: 0.0379 - val_loss: 0.0286\n",
      "Epoch 10/20\n",
      "673/676 [============================>.] - ETA: 0s - loss: 0.0362\n",
      "Epoch 10: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 2ms/step\n",
      "val_f1_score 0.9905381431105854\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0361 - val_loss: 0.0251\n",
      "Epoch 11/20\n",
      "669/676 [============================>.] - ETA: 0s - loss: 0.0368\n",
      "Epoch 11: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9887440758293838\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0366 - val_loss: 0.0295\n",
      "Epoch 12/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0341\n",
      "Epoch 12: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9663941871026339\n",
      "676/676 [==============================] - 6s 9ms/step - loss: 0.0341 - val_loss: 0.0664\n",
      "Epoch 13/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0284\n",
      "Epoch 13: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9917452830188679\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0284 - val_loss: 0.0205\n",
      "Epoch 14/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 0.0325\n",
      "Epoch 14: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9911399881866509\n",
      "676/676 [==============================] - 6s 9ms/step - loss: 0.0324 - val_loss: 0.0224\n",
      "Epoch 15/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 0.0314\n",
      "Epoch 15: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9921955529377117\n",
      "676/676 [==============================] - 6s 9ms/step - loss: 0.0315 - val_loss: 0.0248\n",
      "Epoch 16/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0251\n",
      "Epoch 16: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9824357671650458\n",
      "676/676 [==============================] - 6s 9ms/step - loss: 0.0255 - val_loss: 0.0426\n",
      "Epoch 17/20\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0249\n",
      "Epoch 17: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9930729550478998\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0248 - val_loss: 0.0173\n",
      "Epoch 18/20\n",
      "668/676 [============================>.] - ETA: 0s - loss: 0.0245\n",
      "Epoch 18: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9863460967646186\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0254 - val_loss: 0.0341\n",
      "Epoch 19/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 0.0279\n",
      "Epoch 19: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9886881151755545\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0279 - val_loss: 0.0294\n",
      "Epoch 20/20\n",
      "673/676 [============================>.] - ETA: 0s - loss: 0.0232\n",
      "Epoch 20: val_loss did not improve from 0.09964\n",
      "290/290 [==============================] - 1s 3ms/step\n",
      "val_f1_score 0.9936680901192755\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0234 - val_loss: 0.0189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b91cab80a0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\")\n",
    "model.fit( X_train_pooled_output,train_y,epochs = 20,validation_data = (X_test_pooled_output,test_y),callbacks = [tensorboard_callback,cp_callback,score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### -Observation :\n",
    "###### As we can see from the above training we got best f1-score of 0.9936 which is very good from ML models i.e 0.99"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep_Learning_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env_3.10)",
   "language": "python",
   "name": "tf_env_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
